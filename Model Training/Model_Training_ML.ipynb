{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#Sarcasm Detection on Airline Reviews - Data Preprocessing\n",
        "\n",
        "This notebook demonstrates the steps for preprocessing a dataset for sarcasm detection in Airline Reviews using deep learning. The preprocessing steps include loading the dataset, cleaning the data, and preparing the data for model training.\n",
        "\n",
        "#Dataset Overview\n",
        "We are using a dataset of Airline Reviews which contains the following columns:\n",
        "\n",
        "`Review`: The text of the YouTube comment.\n",
        "\n",
        "`sarcasm`: The target label indicating whether the comment is sarcastic (1) or not (0).\n",
        "\n",
        "\n",
        "Additional features related to airline information.\n",
        "\n",
        "Let's load the dataset and take a look at its structure."
      ],
      "metadata": {
        "id": "G9133Pq57RKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the dataset\n",
        "dataset_path = '/content/drive/My Drive/Airline_Reviews_Labeled.csv'\n",
        "  # Update with your dataset path\n",
        "data = pd.read_csv(dataset_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ayjX-G8zSaTs",
        "outputId": "cdfe9392-1fcd-4bf1-b61e-314df2d8bd50"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Taking subset of the dataset"
      ],
      "metadata": {
        "id": "ehP86X9Y7g9R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Randomly sample 8000 records\n",
        "sampled_data = data.sample(n=8000, random_state=42)"
      ],
      "metadata": {
        "id": "er1CDV2EWtM7"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Splitting the dataset into training and testing data"
      ],
      "metadata": {
        "id": "M0shV1L67mfk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(sampled_data['Review'], sampled_data['sarcasm'], test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "rr39PirBWw1b"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to DataFrame for preprocessing\n",
        "train_data = pd.DataFrame({'text': X_train, 'label': y_train})"
      ],
      "metadata": {
        "id": "pXEOqpW-W1xd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Visualization"
      ],
      "metadata": {
        "id": "aLC9TwN37wDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Describe the dataset\n",
        "print(train_data.describe())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GYOXnnxpW-5U",
        "outputId": "50fa758c-e012-408f-b129-3f84062b655b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             label\n",
            "count  6400.000000\n",
            "mean      0.715625\n",
            "std       0.451151\n",
            "min       0.000000\n",
            "25%       0.000000\n",
            "50%       1.000000\n",
            "75%       1.000000\n",
            "max       1.000000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Shape of the dataset\n",
        "print(train_data.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DGQ_dwTcXIWo",
        "outputId": "5300825a-7f4b-4c7e-828a-489f67888bc2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6400, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# Distribution of labels\n",
        "train_data['label'].value_counts().plot(kind='bar')\n",
        "plt.title('Distribution of Labels')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Count')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "6Ypjk63kXuor",
        "outputId": "09036190-b092-4951-b669-60e258bcd588"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Length of reviews\n",
        "train_data['review_length'] = train_data['text'].apply(len)\n",
        "plt.hist(train_data['review_length'], bins=50)\n",
        "plt.title('Length of Reviews')\n",
        "plt.xlabel('Length')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "SqjU2oG-XqAm",
        "outputId": "bbbba10a-1962-48ff-88cb-c909d46e7e10"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "print(train_data.isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpZwu9EHW4tV",
        "outputId": "0dabab48-5431-4162-c0db-dad8cd08cdf4"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text             0\n",
            "label            0\n",
            "review_length    0\n",
            "dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for duplicates\n",
        "print(train_data.duplicated().sum())\n",
        "\n",
        "# Remove duplicates\n",
        "train_data = train_data.drop_duplicates()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3qG8I-v7XJW5",
        "outputId": "412f8f23-1087-48dc-accc-698654914c2e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List of columns to drop\n",
        "columns_to_drop = [\n",
        "    'Unnamed: 0','Airline Name','Overall_Rating','Review_Title','Review Date',\n",
        "    'Verified','Aircraft','Type Of Traveller','Route', 'Seat Type', 'Date Flown',\n",
        "    'Seat Comfort','Cabin Staff Service', 'Food & Beverages',\n",
        "    'Ground Service', 'Inflight Entertainment',\n",
        "    'Wifi & Connectivity', 'Value For Money','Recommended',\n",
        "]\n",
        "\n",
        "# Drop columns\n",
        "train_data = train_data.drop(columns=columns_to_drop, errors='ignore')\n"
      ],
      "metadata": {
        "id": "8pOgBABUXZS3"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Data Cleaning"
      ],
      "metadata": {
        "id": "gQloAHdN8G08"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Text Cleaning\n",
        "def clean_text(text):\n",
        "    text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n",
        "    text = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', text, flags=re.MULTILINE)  # Remove URLs\n",
        "    text = re.sub(r'\\@\\w+|\\#','', text)  # Remove mentions and hashtags\n",
        "    text = re.sub(r'[^A-Za-z0-9]+', ' ', text)  # Remove special characters\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    return text\n",
        "\n",
        "train_data['clean_text'] = train_data['text'].apply(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6l8PCjBwXvKE",
        "outputId": "0d285e51-3b5b-4915-e003-b7a69c258114"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-33-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization"
      ],
      "metadata": {
        "id": "hQp_D8l18M36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# Tokenize the text\n",
        "train_data['tokenized_text'] = train_data['clean_text'].apply(lambda x: tokenizer.encode(x, add_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H8wfvZEGYUE0",
        "outputId": "e720d728-5032-4e6b-ade5-ebdee271c80a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (717 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Removing Stopwords"
      ],
      "metadata": {
        "id": "nYkOh6eJ8gZ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "# Remove stop words\n",
        "train_data['clean_text'] = train_data['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))"
      ],
      "metadata": {
        "id": "NeHKBfhsYYuC"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Label encoding"
      ],
      "metadata": {
        "id": "xwc4llJ48lmk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "train_data['encoded_label'] = label_encoder.fit_transform(train_data['label'])\n"
      ],
      "metadata": {
        "id": "LBE55nlVZawa"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text vectorization"
      ],
      "metadata": {
        "id": "DunQTsPx8qis"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec\n",
        "import numpy as np\n",
        "# Prepare data for Word2Vec\n",
        "sentences = [text.split() for text in train_data['clean_text']]\n",
        "\n",
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n",
        "\n",
        "# Get Word2Vec vectors for the training data\n",
        "train_data['word2vec'] = train_data['clean_text'].apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n"
      ],
      "metadata": {
        "id": "EGArchm1ZcM_"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Handling imbalanced data"
      ],
      "metadata": {
        "id": "pKhbFIck8uCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Balance the dataset using SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_resampled, y_resampled = smote.fit_resample(train_data['word2vec'].tolist(), train_data['encoded_label'])\n"
      ],
      "metadata": {
        "id": "iQtuu_QNZeQL"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Traning and Testing Machine learning models"
      ],
      "metadata": {
        "id": "4KcNdRJ380lU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Random Forest"
      ],
      "metadata": {
        "id": "0yIBrupo880D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Train Random Forest model\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "rf_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Evaluate on training data\n",
        "y_train_pred_rf = rf_model.predict(X_resampled)\n",
        "print(\"--- Random Forest Training Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_resampled, y_train_pred_rf))\n",
        "\n",
        "# Preprocess the testing data\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "X_test_tokenized = X_test_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "X_test_vectors = X_test_tokenized.apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n",
        "\n",
        "# Ensure all vectors are the same length\n",
        "X_test_vectors = np.array(X_test_vectors.tolist())\n",
        "\n",
        "# Evaluate on testing data\n",
        "y_test_pred_rf = rf_model.predict(X_test_vectors)\n",
        "print(\"--- Random Forest Testing Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_rf))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_rf, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_rf, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred_rf, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jElnMeOxa03F",
        "outputId": "5bdceecb-f37f-417b-9bb5-bb252d1136f5"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Random Forest Training Data ---\n",
            "Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Random Forest Testing Data ---\n",
            "Accuracy: 0.834375\n",
            "Recall: 0.8214035087719298\n",
            "Precision: 0.8000524109014675\n",
            "F1 Score: 0.8088173958133715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##2. Support Vector Machine"
      ],
      "metadata": {
        "id": "h6NrhqMS9G-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "# Train SVM model\n",
        "svm_model = SVC(kernel='linear', random_state=42)\n",
        "svm_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Evaluate on training data\n",
        "y_train_pred_svm = svm_model.predict(X_resampled)\n",
        "print(\"--- SVM Training Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_resampled, y_train_pred_svm))\n",
        "\n",
        "# Preprocess the testing data\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "X_test_tokenized = X_test_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "X_test_vectors = X_test_tokenized.apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n",
        "\n",
        "# Ensure all vectors are the same length\n",
        "X_test_vectors = np.array(X_test_vectors.tolist())\n",
        "\n",
        "# Evaluate on testing data\n",
        "y_test_pred_svm = svm_model.predict(X_test_vectors)\n",
        "print(\"--- SVM Testing Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_svm))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_svm, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_svm, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred_svm, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whAeOhFabzC7",
        "outputId": "e8e4f138-bd15-4d53-bdb0-33f5e3e7d862"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SVM Training Data ---\n",
            "Accuracy: 0.8531789381691064\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SVM Testing Data ---\n",
            "Accuracy: 0.84375\n",
            "Recall: 0.8511812865497076\n",
            "Precision: 0.81256297895233\n",
            "F1 Score: 0.8249777721770664\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Logistic Regression"
      ],
      "metadata": {
        "id": "JgR3dduA9Ly9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train Logistic Regression model\n",
        "lr_model = LogisticRegression(random_state=42)\n",
        "lr_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Evaluate on training data\n",
        "y_train_pred_lr = lr_model.predict(X_resampled)\n",
        "print(\"--- Logistic Regression Training Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_resampled, y_train_pred_lr))\n",
        "\n",
        "# Preprocess the testing data\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "X_test_tokenized = X_test_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "X_test_vectors = X_test_tokenized.apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n",
        "\n",
        "# Ensure all vectors are the same length\n",
        "X_test_vectors = np.array(X_test_vectors.tolist())\n",
        "\n",
        "# Evaluate on testing data\n",
        "y_test_pred_lr = lr_model.predict(X_test_vectors)\n",
        "print(\"--- Logistic Regression Testing Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_lr))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_lr, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_lr, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred_lr, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml2CGuQ9c2Sy",
        "outputId": "98f7bd7f-16ff-42f9-cacd-7ae4361e1d20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Logistic Regression Training Data ---\n",
            "Accuracy: 0.8468429102031899\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Logistic Regression Testing Data ---\n",
            "Accuracy: 0.85\n",
            "Recall: 0.8519766081871345\n",
            "Precision: 0.8181673627568895\n",
            "F1 Score: 0.8302300206376632\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. GaussianNB"
      ],
      "metadata": {
        "id": "JU_foyWw9PWw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "# Train Gaussian Naive Bayes model\n",
        "gnb_model = GaussianNB()\n",
        "gnb_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Evaluate on training data\n",
        "y_train_pred_gnb = gnb_model.predict(X_resampled)\n",
        "print(\"--- Gaussian Naive Bayes Training Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_resampled, y_train_pred_gnb))\n",
        "\n",
        "# Preprocess the testing data\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "X_test_tokenized = X_test_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "X_test_vectors = X_test_tokenized.apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n",
        "\n",
        "# Ensure all vectors are the same length\n",
        "X_test_vectors = np.array(X_test_vectors.tolist())\n",
        "\n",
        "# Evaluate on testing data\n",
        "y_test_pred_gnb = gnb_model.predict(X_test_vectors)\n",
        "print(\"--- Gaussian Naive Bayes Testing Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_gnb))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_gnb, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_gnb, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred_gnb, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHEB4CQ1c359",
        "outputId": "2ef2a527-be1b-468e-adb9-dba8f1d90935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Gaussian Naive Bayes Training Data ---\n",
            "Accuracy: 0.7959362027528949\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Gaussian Naive Bayes Testing Data ---\n",
            "Accuracy: 0.79375\n",
            "Recall: 0.8040701754385965\n",
            "Precision: 0.7640566115924082\n",
            "F1 Score: 0.7731643063725364\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##5. Gradient Boosting Classifier"
      ],
      "metadata": {
        "id": "UZRBI8Bv9TjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "# Train Gradient Boosting model\n",
        "gb_model = GradientBoostingClassifier(random_state=42)\n",
        "gb_model.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Evaluate on training data\n",
        "y_train_pred_gb = gb_model.predict(X_resampled)\n",
        "print(\"--- Gradient Boosting Training Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_resampled, y_train_pred_gb))\n",
        "\n",
        "# Preprocess the testing data\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "X_test_tokenized = X_test_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "X_test_vectors = X_test_tokenized.apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n",
        "\n",
        "# Ensure all vectors are the same length\n",
        "X_test_vectors = np.array(X_test_vectors.tolist())\n",
        "\n",
        "# Evaluate on testing data\n",
        "y_test_pred_gb = gb_model.predict(X_test_vectors)\n",
        "print(\"--- Gradient Boosting Testing Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_gb))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_gb, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_gb, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred_gb, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiuP4t3Cc6fe",
        "outputId": "f1b00764-4250-4435-c57e-a69c83f681ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Gradient Boosting Training Data ---\n",
            "Accuracy: 0.8762289709416649\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Gradient Boosting Testing Data ---\n",
            "Accuracy: 0.829375\n",
            "Recall: 0.836701754385965\n",
            "Precision: 0.7979384003974168\n",
            "F1 Score: 0.8096545412948983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion\n",
        "\n",
        "###Models with thier accuracies\n",
        "\n",
        "*   Random Forest Classifier - 0.83\n",
        "*   Support Vector Machine   - 0.84\n",
        "*   LogisticRegression Model - 0.85\n",
        "*   GaussianNB               - 0.79\n",
        "*   Gradient Bossting        - 0.82\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2FRpOcXOWzA4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "dXVxsjHfS0xT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###1. Random Forest"
      ],
      "metadata": {
        "id": "KpNeTGIVTGI0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter grid for RandomForestClassifier\n",
        "param_grid = {\n",
        "    'n_estimators': [50, 100],\n",
        "    'max_depth': [None, 10],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2],\n",
        "    'max_features': ['auto', 'sqrt']\n",
        "}\n",
        "\n",
        "\n",
        "# Instantiate the Random Forest classifier\n",
        "rf_model = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Instantiate the grid search\n",
        "grid_search = GridSearchCV(estimator=rf_model, param_grid=param_grid,\n",
        "                           cv=3, n_jobs=-1, verbose=2, scoring='f1_macro')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model on training data\n",
        "best_rf_model = grid_search.best_estimator_\n",
        "y_train_pred_rf = best_rf_model.predict(X_resampled)\n",
        "print(\"--- Random Forest Training Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_resampled, y_train_pred_rf))\n",
        "print(\"Recall:\", recall_score(y_resampled, y_train_pred_rf, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_resampled, y_train_pred_rf, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_resampled, y_train_pred_rf, average='macro'))\n",
        "\n",
        "# Preprocess the testing data (assuming X_test and y_test are defined)\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "X_test_tokenized = X_test_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "X_test_vectors = X_test_tokenized.apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n",
        "\n",
        "# Ensure all vectors are the same length\n",
        "X_test_vectors = np.array(X_test_vectors.tolist())\n",
        "\n",
        "# Evaluate the best model on testing data\n",
        "y_test_pred_rf = best_rf_model.predict(X_test_vectors)\n",
        "print(\"--- Random Forest Testing Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_rf))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_rf, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_rf, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred_rf, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxPbmjEYjRzL",
        "outputId": "9760cfbf-341e-42ec-f96a-a3dabd2f3712"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/ensemble/_forest.py:424: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:  {'max_depth': None, 'max_features': 'auto', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n",
            "--- Random Forest Training Data ---\n",
            "Accuracy: 1.0\n",
            "Recall: 1.0\n",
            "Precision: 1.0\n",
            "F1 Score: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Random Forest Testing Data ---\n",
            "Accuracy: 0.834375\n",
            "Recall: 0.8214035087719298\n",
            "Precision: 0.8000524109014675\n",
            "F1 Score: 0.8088173958133715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Support Vector Machine"
      ],
      "metadata": {
        "id": "nAy8W0WHTRU3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'degree': [3, 4, 5]  # Only relevant for 'poly' kernel\n",
        "}\n",
        "\n",
        "# Instantiate the SVM classifier\n",
        "svm_model = SVC(random_state=42)\n",
        "\n",
        "# Instantiate the grid search\n",
        "grid_search = GridSearchCV(estimator=svm_model, param_grid=param_grid,\n",
        "                           cv=3, n_jobs=-1, verbose=2, scoring='f1_macro')\n",
        "\n",
        "# Fit the grid search to the data\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Print the best parameters\n",
        "print(\"Best parameters found: \", grid_search.best_params_)\n",
        "\n",
        "# Evaluate the best model on training data\n",
        "best_svm_model = grid_search.best_estimator_\n",
        "y_train_pred_svm = best_svm_model.predict(X_resampled)\n",
        "print(\"--- SVM Training Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_resampled, y_train_pred_svm))\n",
        "print(\"Recall:\", recall_score(y_resampled, y_train_pred_svm, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_resampled, y_train_pred_svm, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_resampled, y_train_pred_svm, average='macro'))\n",
        "\n",
        "# Preprocess the testing data\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "X_test_tokenized = X_test_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "X_test_vectors = X_test_tokenized.apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n",
        "\n",
        "# Ensure all vectors are the same length\n",
        "X_test_vectors = np.array(X_test_vectors.tolist())\n",
        "\n",
        "# Evaluate the best model on testing data\n",
        "y_test_pred_svm = best_svm_model.predict(X_test_vectors)\n",
        "print(\"--- SVM Testing Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_svm))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_svm, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_svm, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred_svm, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7tLZ1f9MIas",
        "outputId": "23fae9f1-d326-490f-bb8d-5d4f07f2b8b6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 96 candidates, totalling 288 fits\n",
            "Best parameters found:  {'C': 100, 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf'}\n",
            "--- SVM Training Data ---\n",
            "Accuracy: 0.883111208214988\n",
            "Recall: 0.8831112082149879\n",
            "Precision: 0.8856039384044159\n",
            "F1 Score: 0.8829219960169397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- SVM Testing Data ---\n",
            "Accuracy: 0.8525\n",
            "Recall: 0.855578947368421\n",
            "Precision: 0.8209459174142244\n",
            "F1 Score: 0.8332202623247398\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Logistic Regression"
      ],
      "metadata": {
        "id": "0kDD68LL9dSU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
        "\n",
        "# Define the parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
        "}\n",
        "\n",
        "# Initialize the Logistic Regression model\n",
        "lr_model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "\n",
        "# Initialize GridSearchCV\n",
        "grid_search = GridSearchCV(estimator=lr_model, param_grid=param_grid, cv=5, scoring='f1_macro', n_jobs=-1)\n",
        "\n",
        "# Fit GridSearchCV\n",
        "grid_search.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Get the best model\n",
        "best_lr_model = grid_search.best_estimator_\n",
        "\n",
        "# Evaluate the best model on the training data\n",
        "y_train_pred_lr = best_lr_model.predict(X_resampled)\n",
        "print(\"--- Best Logistic Regression Model on Training Data ---\")\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Accuracy:\", accuracy_score(y_resampled, y_train_pred_lr))\n",
        "print(\"Recall:\", recall_score(y_resampled, y_train_pred_lr, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_resampled, y_train_pred_lr, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_resampled, y_train_pred_lr, average='macro'))\n",
        "\n",
        "# Preprocess the testing data\n",
        "X_test_clean = X_test.apply(clean_text)\n",
        "X_test_tokenized = X_test_clean.apply(lambda x: ' '.join([word for word in x.split() if word not in stop_words]))\n",
        "X_test_vectors = X_test_tokenized.apply(lambda x: np.mean([word2vec_model.wv[word] for word in x.split() if word in word2vec_model.wv], axis=0))\n",
        "\n",
        "# Ensure all vectors are the same length\n",
        "X_test_vectors = np.array(X_test_vectors.tolist())\n",
        "\n",
        "# Evaluate the best model on the testing data\n",
        "y_test_pred_lr = best_lr_model.predict(X_test_vectors)\n",
        "print(\"--- Best Logistic Regression Model on Testing Data ---\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_lr))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred_lr, average='macro'))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred_lr, average='macro'))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_test_pred_lr, average='macro'))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q0jMK31eSqS",
        "outputId": "2e08f040-c5fb-4035-e0aa-c8002f13a6fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
            "225 fits failed out of a total of 500.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 64, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1291, in fit\n",
            "    fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose, prefer=prefer)(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 63, in __call__\n",
            "    return super().__call__(iterable_with_config)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1918, in __call__\n",
            "    return output if self.return_generator else list(output)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/joblib/parallel.py\", line 1847, in _get_sequential_output\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/parallel.py\", line 123, in __call__\n",
            "    return self.function(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 521, in _logistic_regression_path\n",
            "    alpha = (1.0 / C) * (1 - l1_ratio)\n",
            "TypeError: unsupported operand type(s) for -: 'int' and 'NoneType'\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
            "ValueError: penalty='none' is not supported for the liblinear solver\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.80495043        nan 0.80530861 0.81576799\n",
            " 0.81576799 0.8164704  0.81576799 0.81576799        nan        nan\n",
            "        nan        nan        nan 0.86788405 0.86821917        nan\n",
            " 0.86362455 0.85924919        nan        nan 0.82623512        nan\n",
            " 0.82696369 0.83297534 0.83297534 0.8340767  0.83297534 0.83297534\n",
            "        nan        nan        nan        nan        nan 0.86788405\n",
            " 0.86821917        nan 0.86362455 0.85924919        nan        nan\n",
            " 0.84767135        nan 0.84865089 0.84470113 0.84470113 0.84404738\n",
            " 0.84470113 0.84470113        nan        nan        nan        nan\n",
            "        nan 0.86788405 0.86821917        nan 0.86362455 0.85924919\n",
            "        nan        nan 0.86307433        nan 0.85783353 0.85618986\n",
            " 0.85618986 0.8562997  0.85629884 0.85629884        nan        nan\n",
            "        nan        nan        nan 0.86788405 0.86821917        nan\n",
            " 0.86362455 0.85924919        nan        nan 0.86788908        nan\n",
            " 0.85892091 0.86209393 0.8619853  0.86187433 0.86077868 0.85903537\n",
            "        nan        nan        nan        nan        nan 0.86788405\n",
            " 0.86821917        nan 0.86362455 0.85924919]\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1173: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:1181: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Best Logistic Regression Model on Training Data ---\n",
            "Best Parameters: {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}\n",
            "Accuracy: 0.8731701988201879\n",
            "Recall: 0.8731701988201879\n",
            "Precision: 0.8734226240290792\n",
            "F1 Score: 0.8731487616814941\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-b8df1234f44a>:9: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  text = BeautifulSoup(text, \"html.parser\").get_text()  # Remove HTML tags\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Best Logistic Regression Model on Testing Data ---\n",
            "Accuracy: 0.87\n",
            "Recall: 0.8661988304093566\n",
            "Precision: 0.8397405515016727\n",
            "F1 Score: 0.8504885179854047\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. GaussianNB"
      ],
      "metadata": {
        "id": "HZ8STx-1TbfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import make_scorer, accuracy_score, recall_score, precision_score, f1_score\n",
        "import numpy as np\n",
        "\n",
        "# Assuming X_resampled and y_resampled are your training data\n",
        "# Assuming X_test_vectors and y_test are your testing data\n",
        "\n",
        "# Define the GNB model\n",
        "gnb_model = GaussianNB()\n",
        "\n",
        "# Parameters to tune\n",
        "parameters = {\n",
        "    'priors': [None, [0.1, 0.9], [0.3, 0.7], [0.5, 0.5], [0.7, 0.3], [0.9, 0.1]]\n",
        "}\n",
        "\n",
        "# Choose a scoring method\n",
        "scoring = {\n",
        "    'accuracy': make_scorer(accuracy_score),\n",
        "    'recall': make_scorer(recall_score, average='macro'),\n",
        "    'precision': make_scorer(precision_score, average='macro'),\n",
        "    'f1_score': make_scorer(f1_score, average='macro')\n",
        "}\n",
        "\n",
        "# Perform grid search cross-validation\n",
        "clf = GridSearchCV(gnb_model, parameters, scoring=scoring, refit='accuracy', cv=5)\n",
        "clf.fit(X_resampled, y_resampled)\n",
        "\n",
        "# Print the best parameters and results\n",
        "print(\"Best parameters found:\")\n",
        "print(clf.best_params_)\n",
        "print()\n",
        "\n",
        "print(\"Grid search results:\")\n",
        "means = clf.cv_results_['mean_test_accuracy']\n",
        "stds = clf.cv_results_['std_test_accuracy']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"Accuracy: %0.3f (+/-%0.03f) for %r\"\n",
        "          % (mean, std * 2, params))\n",
        "    print(\"Recall:\", clf.cv_results_['mean_test_recall'][np.argmax(means)])\n",
        "    print(\"Precision:\", clf.cv_results_['mean_test_precision'][np.argmax(means)])\n",
        "    print(\"F1 Score:\", clf.cv_results_['mean_test_f1_score'][np.argmax(means)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEh2MZkmRu32",
        "outputId": "3831a5e4-a907-4f4c-bb02-910ad67ff11b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters found:\n",
            "{'priors': [0.9, 0.1]}\n",
            "\n",
            "Grid search results:\n",
            "Accuracy: 0.795 (+/-0.015) for {'priors': None}\n",
            "Recall: 0.7964813754265396\n",
            "Precision: 0.7994210886118663\n",
            "F1 Score: 0.7959813091457631\n",
            "Accuracy: 0.793 (+/-0.014) for {'priors': [0.1, 0.9]}\n",
            "Recall: 0.7964813754265396\n",
            "Precision: 0.7994210886118663\n",
            "F1 Score: 0.7959813091457631\n",
            "Accuracy: 0.793 (+/-0.014) for {'priors': [0.3, 0.7]}\n",
            "Recall: 0.7964813754265396\n",
            "Precision: 0.7994210886118663\n",
            "F1 Score: 0.7959813091457631\n",
            "Accuracy: 0.795 (+/-0.015) for {'priors': [0.5, 0.5]}\n",
            "Recall: 0.7964813754265396\n",
            "Precision: 0.7994210886118663\n",
            "F1 Score: 0.7959813091457631\n",
            "Accuracy: 0.796 (+/-0.013) for {'priors': [0.7, 0.3]}\n",
            "Recall: 0.7964813754265396\n",
            "Precision: 0.7994210886118663\n",
            "F1 Score: 0.7959813091457631\n",
            "Accuracy: 0.796 (+/-0.014) for {'priors': [0.9, 0.1]}\n",
            "Recall: 0.7964813754265396\n",
            "Precision: 0.7994210886118663\n",
            "F1 Score: 0.7959813091457631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Conclusion After hyperparameter tuning\n",
        "\n",
        "###Models with thier accuracies\n",
        "\n",
        "*   Random Forest Classifier - 0.83\n",
        "*   Support Vector Machine   - 0.85\n",
        "*   LogisticRegression Model - 0.87\n",
        "*   GaussianNB               - 0.79\n",
        "*   Gradient Bossting        - 0.82\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eWi2URDn9oAB"
      }
    }
  ]
}